{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model awal ceunah.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjOAfhgd__Sp"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp_nvHnh_tDo"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfyZKowNAQ4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d67d97b-497d-40d1-f717-d01509c5822b"
      },
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print('\\u2022 Using TensorFlow Version:', tf.__version__)\n",
        "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "• Using TensorFlow Version: 2.8.0\n",
            "WARNING:tensorflow:From <ipython-input-1-c8c510cd44fc>:9: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "• GPU Device Found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tadPBTEiAprt"
      },
      "source": [
        "# Mount Drive to Access The Data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t9baBf758xD",
        "outputId": "278cf94d-3f81-48df-d84f-b85835b9e997"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/Dataset/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBqhFTc5bDpI",
        "outputId": "d68a345e-3a75-41af-eb81-777fac39650b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Dataset\n",
            "train  validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Q4C7WILELz"
      },
      "source": [
        "The class names are not included with the dataset, so we will specify them here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eAv71FRm4JE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3a2664-1fc1-402f-e0ed-63ee56a4ae26"
      },
      "source": [
        "import os\n",
        "\n",
        "akel_dir = os.path.join('train/Akar Kelapa')\n",
        "bakmi_dir = os.path.join('train/Bakmi')\n",
        "bakso_dir = os.path.join('train/Bakso')\n",
        "bangkit_dir = os.path.join('train/Kue Bangkit')\n",
        "tambang_dir = os.path.join('train/Kue Tambang')\n",
        "nasgor_dir = os.path.join('train/Nasi Goreng')\n",
        "nastar_dir = os.path.join('train/Nastar')\n",
        "onde_dir = os.path.join('train/Onde Onde')\n",
        "rendang_dir = os.path.join('train/Rendang')\n",
        "sate_dir = os.path.join('train/Sate')\n",
        "semur_dir = os.path.join('train/Semur Tahu')\n",
        "tempe_dir = os.path.join('train/Tempe Orek')\n",
        "\n",
        "print('total training akar kelapa images:', len(os.listdir(akel_dir)))\n",
        "print('total training bakmi images:', len(os.listdir(bakmi_dir)))\n",
        "print('total training bakso images:', len(os.listdir(bakso_dir)))\n",
        "print('total training kue bangkit images:', len(os.listdir(bangkit_dir)))\n",
        "print('total training kue tambang images:', len(os.listdir(tambang_dir)))\n",
        "print('total training nasi goreng images:', len(os.listdir(nasgor_dir)))\n",
        "print('total training nastar images:', len(os.listdir(nastar_dir)))\n",
        "print('total training onde onde images:', len(os.listdir(onde_dir)))\n",
        "print('total training rendang images:', len(os.listdir(rendang_dir)))\n",
        "print('total training sate images:', len(os.listdir(sate_dir)))\n",
        "print('total training semur tahu images:', len(os.listdir(semur_dir)))\n",
        "print('total training tempe images:', len(os.listdir(tempe_dir)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training akar kelapa images: 30\n",
            "total training bakmi images: 30\n",
            "total training bakso images: 30\n",
            "total training kue bangkit images: 30\n",
            "total training kue tambang images: 30\n",
            "total training nasi goreng images: 30\n",
            "total training nastar images: 30\n",
            "total training onde onde images: 30\n",
            "total training rendang images: 30\n",
            "total training sate images: 30\n",
            "total training semur tahu images: 30\n",
            "total training tempe images: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iubWCThbdN8K"
      },
      "source": [
        "# The images in the dataset are 28 by 28 pixels.\n",
        "# IMG_SIZE = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAkuq0V0Aw2X"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5SIivkunKCC"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwyhsyGydHDl"
      },
      "source": [
        "# # EXERCISE: Write a function to normalize the images.\n",
        "\n",
        "# def format_example(image, label):\n",
        "#     # Cast image to float32\n",
        "#     image = # YOUR CODE HERE\n",
        "        \n",
        "#     # Normalize the image in the range [0, 1]\n",
        "#     image = # YOUR CODE HERE\n",
        "    \n",
        "#     return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAlBlXOUMwqe"
      },
      "source": [
        "# Specify the batch size\n",
        "# BATCH_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-topQaOm_LM"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dJbV-jNLEL2"
      },
      "source": [
        "```\n",
        "Model: \"sequential\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
        "_________________________________________________________________\n",
        "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
        "_________________________________________________________________\n",
        "flatten (Flatten)            (None, 3872)              0         \n",
        "_________________________________________________________________\n",
        "dense (Dense)                (None, 64)                247872    \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 10)                650       \n",
        "=================================================================\n",
        "Total params: 253,322\n",
        "Trainable params: 253,322\n",
        "Non-trainable params: 0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDqcwksFB1bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe575d6-96f8-43f3-c62f-4a49865ed83e"
      },
      "source": [
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"train/\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1.0/255.,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = \"validation/\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical'\n",
        ")\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, epochs=25 , validation_data = validation_generator, verbose = 1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 360 images belonging to 12 classes.\n",
            "Found 122 images belonging to 12 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 148, 148, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 74, 74, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 72, 72, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 17, 17, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 12)                6156      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,478,092\n",
            "Trainable params: 3,478,092\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "12/12 [==============================] - 7s 507ms/step - loss: 3.0172 - accuracy: 0.0722 - val_loss: 2.4806 - val_accuracy: 0.0738\n",
            "Epoch 2/25\n",
            "12/12 [==============================] - 5s 444ms/step - loss: 2.4819 - accuracy: 0.1056 - val_loss: 2.4406 - val_accuracy: 0.1066\n",
            "Epoch 3/25\n",
            "12/12 [==============================] - 5s 451ms/step - loss: 2.5167 - accuracy: 0.1111 - val_loss: 2.4939 - val_accuracy: 0.0902\n",
            "Epoch 4/25\n",
            "12/12 [==============================] - 5s 445ms/step - loss: 2.4493 - accuracy: 0.1194 - val_loss: 3.3981 - val_accuracy: 0.0820\n",
            "Epoch 5/25\n",
            "12/12 [==============================] - 5s 441ms/step - loss: 2.5352 - accuracy: 0.1167 - val_loss: 2.3120 - val_accuracy: 0.1230\n",
            "Epoch 6/25\n",
            "12/12 [==============================] - 5s 439ms/step - loss: 2.3444 - accuracy: 0.1500 - val_loss: 2.2546 - val_accuracy: 0.1803\n",
            "Epoch 7/25\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 2.2151 - accuracy: 0.2167 - val_loss: 2.0385 - val_accuracy: 0.3115\n",
            "Epoch 8/25\n",
            "12/12 [==============================] - 5s 451ms/step - loss: 2.7173 - accuracy: 0.1361 - val_loss: 2.2158 - val_accuracy: 0.2213\n",
            "Epoch 9/25\n",
            "12/12 [==============================] - 5s 448ms/step - loss: 2.1917 - accuracy: 0.2167 - val_loss: 1.9445 - val_accuracy: 0.3525\n",
            "Epoch 10/25\n",
            "12/12 [==============================] - 5s 457ms/step - loss: 2.1931 - accuracy: 0.2500 - val_loss: 1.7924 - val_accuracy: 0.3770\n",
            "Epoch 11/25\n",
            "12/12 [==============================] - 5s 450ms/step - loss: 2.0165 - accuracy: 0.2750 - val_loss: 2.4900 - val_accuracy: 0.2623\n",
            "Epoch 12/25\n",
            "12/12 [==============================] - 5s 455ms/step - loss: 2.0728 - accuracy: 0.2639 - val_loss: 2.7886 - val_accuracy: 0.2049\n",
            "Epoch 13/25\n",
            "12/12 [==============================] - 5s 450ms/step - loss: 1.9504 - accuracy: 0.3194 - val_loss: 1.8785 - val_accuracy: 0.3607\n",
            "Epoch 14/25\n",
            "12/12 [==============================] - 5s 452ms/step - loss: 2.0410 - accuracy: 0.2528 - val_loss: 1.7777 - val_accuracy: 0.3852\n",
            "Epoch 15/25\n",
            "12/12 [==============================] - 5s 438ms/step - loss: 1.9941 - accuracy: 0.3056 - val_loss: 1.7722 - val_accuracy: 0.3689\n",
            "Epoch 16/25\n",
            "12/12 [==============================] - 5s 434ms/step - loss: 1.9778 - accuracy: 0.3444 - val_loss: 1.7474 - val_accuracy: 0.4344\n",
            "Epoch 17/25\n",
            "12/12 [==============================] - 5s 448ms/step - loss: 1.7962 - accuracy: 0.3500 - val_loss: 1.7532 - val_accuracy: 0.3443\n",
            "Epoch 18/25\n",
            "12/12 [==============================] - 5s 439ms/step - loss: 1.8227 - accuracy: 0.3611 - val_loss: 2.3777 - val_accuracy: 0.2541\n",
            "Epoch 19/25\n",
            "12/12 [==============================] - 5s 441ms/step - loss: 1.8236 - accuracy: 0.3278 - val_loss: 1.7337 - val_accuracy: 0.3279\n",
            "Epoch 20/25\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 1.8274 - accuracy: 0.3750 - val_loss: 1.5042 - val_accuracy: 0.4836\n",
            "Epoch 21/25\n",
            "12/12 [==============================] - 5s 444ms/step - loss: 1.7592 - accuracy: 0.4056 - val_loss: 1.6120 - val_accuracy: 0.4426\n",
            "Epoch 22/25\n",
            "12/12 [==============================] - 5s 443ms/step - loss: 1.6182 - accuracy: 0.4222 - val_loss: 1.4478 - val_accuracy: 0.5082\n",
            "Epoch 23/25\n",
            "12/12 [==============================] - 5s 443ms/step - loss: 1.6882 - accuracy: 0.3889 - val_loss: 1.5108 - val_accuracy: 0.4754\n",
            "Epoch 24/25\n",
            "12/12 [==============================] - 5s 451ms/step - loss: 1.7531 - accuracy: 0.3722 - val_loss: 1.5821 - val_accuracy: 0.4344\n",
            "Epoch 25/25\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 1.5790 - accuracy: 0.4222 - val_loss: 5.6194 - val_accuracy: 0.1557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGlNoRtzCP4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7a0aaa-f880-401a-e9a7-6f2dd8d7c5b6"
      },
      "source": [
        "#Mengurangi dan memodifikasi layer (So far, ini yang pas walau acc-nya masih kecil)\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, epochs=25 , validation_data = validation_generator, verbose = 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 148, 148, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 74, 74, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 72, 72, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 36, 36, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 17, 17, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               4735104   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 12)                1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,849,228\n",
            "Trainable params: 4,849,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "12/12 [==============================] - 6s 482ms/step - loss: 4.0944 - accuracy: 0.0778 - val_loss: 2.4132 - val_accuracy: 0.0902\n",
            "Epoch 2/25\n",
            "12/12 [==============================] - 5s 438ms/step - loss: 2.4718 - accuracy: 0.1250 - val_loss: 2.4964 - val_accuracy: 0.1230\n",
            "Epoch 3/25\n",
            "12/12 [==============================] - 5s 448ms/step - loss: 2.4354 - accuracy: 0.1194 - val_loss: 2.3849 - val_accuracy: 0.1885\n",
            "Epoch 4/25\n",
            "12/12 [==============================] - 5s 436ms/step - loss: 2.3541 - accuracy: 0.1667 - val_loss: 2.3130 - val_accuracy: 0.2459\n",
            "Epoch 5/25\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 2.3614 - accuracy: 0.1472 - val_loss: 2.2841 - val_accuracy: 0.1557\n",
            "Epoch 6/25\n",
            "12/12 [==============================] - 5s 450ms/step - loss: 2.2275 - accuracy: 0.2472 - val_loss: 2.3445 - val_accuracy: 0.1393\n",
            "Epoch 7/25\n",
            "12/12 [==============================] - 5s 462ms/step - loss: 2.2499 - accuracy: 0.2444 - val_loss: 2.0967 - val_accuracy: 0.2541\n",
            "Epoch 8/25\n",
            "12/12 [==============================] - 5s 456ms/step - loss: 2.1524 - accuracy: 0.2472 - val_loss: 1.9281 - val_accuracy: 0.3197\n",
            "Epoch 9/25\n",
            "12/12 [==============================] - 5s 473ms/step - loss: 2.0428 - accuracy: 0.3222 - val_loss: 1.9739 - val_accuracy: 0.3443\n",
            "Epoch 10/25\n",
            "12/12 [==============================] - 5s 429ms/step - loss: 2.1444 - accuracy: 0.2639 - val_loss: 1.9500 - val_accuracy: 0.3689\n",
            "Epoch 11/25\n",
            "12/12 [==============================] - 6s 502ms/step - loss: 1.9345 - accuracy: 0.3361 - val_loss: 2.0229 - val_accuracy: 0.2705\n",
            "Epoch 12/25\n",
            "12/12 [==============================] - 5s 459ms/step - loss: 1.8711 - accuracy: 0.3389 - val_loss: 2.1226 - val_accuracy: 0.2213\n",
            "Epoch 13/25\n",
            "12/12 [==============================] - 5s 443ms/step - loss: 1.8694 - accuracy: 0.3750 - val_loss: 1.8679 - val_accuracy: 0.3115\n",
            "Epoch 14/25\n",
            "12/12 [==============================] - 5s 479ms/step - loss: 1.8657 - accuracy: 0.3333 - val_loss: 1.6272 - val_accuracy: 0.4098\n",
            "Epoch 15/25\n",
            "12/12 [==============================] - 5s 449ms/step - loss: 1.8057 - accuracy: 0.3472 - val_loss: 1.9756 - val_accuracy: 0.3279\n",
            "Epoch 16/25\n",
            "12/12 [==============================] - 5s 444ms/step - loss: 1.7103 - accuracy: 0.4111 - val_loss: 1.8584 - val_accuracy: 0.3934\n",
            "Epoch 17/25\n",
            "12/12 [==============================] - 5s 480ms/step - loss: 1.6312 - accuracy: 0.4583 - val_loss: 1.9847 - val_accuracy: 0.3689\n",
            "Epoch 18/25\n",
            "12/12 [==============================] - 5s 436ms/step - loss: 1.8797 - accuracy: 0.3778 - val_loss: 1.5185 - val_accuracy: 0.4262\n",
            "Epoch 19/25\n",
            "12/12 [==============================] - 5s 447ms/step - loss: 1.7549 - accuracy: 0.4167 - val_loss: 1.4086 - val_accuracy: 0.4836\n",
            "Epoch 20/25\n",
            "12/12 [==============================] - 5s 441ms/step - loss: 1.5621 - accuracy: 0.4417 - val_loss: 1.5477 - val_accuracy: 0.4836\n",
            "Epoch 21/25\n",
            "12/12 [==============================] - 5s 452ms/step - loss: 1.5288 - accuracy: 0.4444 - val_loss: 2.3550 - val_accuracy: 0.3361\n",
            "Epoch 22/25\n",
            "12/12 [==============================] - 5s 449ms/step - loss: 1.4329 - accuracy: 0.5111 - val_loss: 1.9067 - val_accuracy: 0.3443\n",
            "Epoch 23/25\n",
            "12/12 [==============================] - 5s 447ms/step - loss: 1.5890 - accuracy: 0.4833 - val_loss: 1.6235 - val_accuracy: 0.4098\n",
            "Epoch 24/25\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 1.5535 - accuracy: 0.4389 - val_loss: 1.6405 - val_accuracy: 0.4426\n",
            "Epoch 25/25\n",
            "12/12 [==============================] - 5s 441ms/step - loss: 1.3819 - accuracy: 0.5083 - val_loss: 1.4623 - val_accuracy: 0.4754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mengurangi epochs\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_generator, epochs=10 , validation_data = validation_generator, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqr3d-ZjfKqd",
        "outputId": "48b13e7f-f7ed-415b-e1e1-430a5bde03b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 6s 475ms/step - loss: 2.2142 - accuracy: 0.3833 - val_loss: 1.7140 - val_accuracy: 0.3934\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 5s 449ms/step - loss: 1.5534 - accuracy: 0.4556 - val_loss: 1.3647 - val_accuracy: 0.4836\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 5s 444ms/step - loss: 1.7200 - accuracy: 0.4444 - val_loss: 1.4148 - val_accuracy: 0.4918\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 1.4343 - accuracy: 0.4861 - val_loss: 1.3930 - val_accuracy: 0.4508\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 5s 451ms/step - loss: 1.4675 - accuracy: 0.4972 - val_loss: 2.2483 - val_accuracy: 0.4180\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 5s 446ms/step - loss: 1.6602 - accuracy: 0.4500 - val_loss: 1.4488 - val_accuracy: 0.4344\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 5s 471ms/step - loss: 1.4388 - accuracy: 0.5000 - val_loss: 1.4672 - val_accuracy: 0.4426\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 5s 454ms/step - loss: 1.5865 - accuracy: 0.4806 - val_loss: 1.3144 - val_accuracy: 0.5574\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 5s 447ms/step - loss: 1.4145 - accuracy: 0.5306 - val_loss: 1.8299 - val_accuracy: 0.4098\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 5s 443ms/step - loss: 1.4251 - accuracy: 0.4778 - val_loss: 1.2770 - val_accuracy: 0.6066\n"
          ]
        }
      ]
    }
  ]
}